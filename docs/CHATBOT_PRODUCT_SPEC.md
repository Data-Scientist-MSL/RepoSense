# RepoSense ChatBot: Complete Product Specification

**Version:** 1.0  
**Status:** Ready for Implementation  
**Author:** Product Architecture Team  
**Date:** 2026-01-21

---

## Executive Summary

RepoSense ChatBot is an **Intent-Driven Orchestration Assistant** embedded in VS Code‚Äînot a generic copilot, but an enterprise-grade tool that understands repository state and executes complex testing workflows with explicit governance.

**Core Mission:** Transform ad-hoc testing activities into governed, audited, evidence-based processes through conversational orchestration.

**Key Differentiators:**
- ‚úÖ Intent-driven (not free-form chat)
- ‚úÖ Multi-modal (5 conversation modes)
- ‚úÖ Multi-channel (right-click, TreeView, palette, chat, automatic)
- ‚úÖ Safety-first (confirmations, diffs, audit trails)
- ‚úÖ Evidence-rich (screenshots, logs, reports)
- ‚úÖ Fully integrated (uses RunOrchestrator state machine)

---

## 1. Product Vision

### What It Is NOT
- ‚ùå A general-purpose chatbot ("Ask anything")
- ‚ùå A code copilot for writing code
- ‚ùå A documentation assistant
- ‚ùå A free-form conversation tool

### What It IS
- ‚úÖ A test orchestration assistant for a repo owner
- ‚úÖ An API governance expert embedded in VS Code
- ‚úÖ A workflow executor (plan ‚Üí generate ‚Üí run ‚Üí report)
- ‚úÖ An evidence collector for compliance/audit

### Mental Model

```
User Intent
  ‚Üì
ChatBot classifies intent (what does the user want?)
  ‚Üì
ChatBot plans actions (what steps to take?)
  ‚Üì
ChatBot shows diffs/previews (what will happen?)
  ‚Üì
User approves
  ‚Üì
ChatBot executes (coordinates services, captures evidence)
  ‚Üì
ChatBot provides evidence (links to results, artifacts)
  ‚Üì
User exports for compliance
```

---

## 2. Canonical Intent Categories

**All user inputs map to 5 intents:**

### A. ANALYZE Intent (Read-Only Questions)
**User wants to understand current state**

```
User: "Why is this endpoint unused?"
ChatBot: Explains gap, shows impact, suggests next steps
Services: AnalysisEngine (read-only)
Result: Explanation + evidence
```

**Subtypes:**
- EXPLAIN_GAPS ‚Äî "What are all the gaps?"
- EXPLAIN_GAP_DETAIL ‚Äî "Why is this gap?"
- UNDERSTAND_IMPACT ‚Äî "What will break?"
- IDENTIFY_PRIORITY ‚Äî "Which gaps are critical?"
- ASSESS_CRITICALITY ‚Äî "Should we fix this?"
- EVALUATE_RISK ‚Äî "What's the overall risk?"

**Safety Tier:** ‚úÖ SAFE (no confirmation needed)

### B. DECIDE Intent (Planning & Strategy)
**User wants a roadmap**

```
User: "Help me create a remediation plan"
ChatBot: Suggests 3-step approach with effort estimates
Services: AnalysisEngine, PerformanceMonitor
Result: Structured plan with options
```

**Subtypes:**
- RECOMMEND_ORDER ‚Äî "What should we do first?"
- (All planning questions)

**Safety Tier:** ‚úÖ SAFE (read-only analysis)

### C. GENERATE Intent (Creating Artifacts)
**User wants tests/code generated**

```
User: "Generate tests for critical gaps"
ChatBot: Shows diff, asks confirmation, writes files
Services: TestGenerationService, ArtifactStore
Result: Generated files (pending apply)
```

**Subtypes:**
- GENERATE_TESTS ‚Äî "Create tests for endpoints"
- GENERATE_TESTS_SPECIFIC ‚Äî "Use Playwright only"
- PROPOSE_REMEDIATION ‚Äî "Suggest a fix"

**Safety Tier:** ‚ö†Ô∏è MEDIUM (requires diff + confirmation)

### D. EXECUTE Intent (Running Tests)
**User wants to validate changes**

```
User: "Run the tests now"
ChatBot: Shows real-time progress, streams results
Services: TestExecutor, RunOrchestrator
Result: Test results + execution evidence
```

**Subtypes:**
- RUN_TESTS ‚Äî "Execute all tests"
- RUN_VALIDATION ‚Äî "Validate these changes"
- RERUN_WITH_DEBUG ‚Äî "Why did this fail?"

**Safety Tier:** ‚ö†Ô∏è MEDIUM (requires confirmation)

### E. REPORT Intent (Documentation & Evidence)
**User wants compliance documentation**

```
User: "Generate a UAT report"
ChatBot: Creates signed, immutable report with evidence
Services: ReportGenerator, ArtifactStore
Result: PDF/MD report + evidence archive
```

**Subtypes:**
- GENERATE_UAT_REPORT ‚Äî "Create formal report"
- EXPORT_EVIDENCE ‚Äî "Package results"
- CREATE_EXECUTIVE_SUMMARY ‚Äî "C-level summary"
- SHOW_COVERAGE_DELTA ‚Äî "Before/after comparison"

**Safety Tier:** ‚úÖ SAFE (read-only export)

---

## 3. Conversation Modes

**Mode = conversation context + response style + available actions**

| Mode | Purpose | Tone | Available Intents | Evidence Emphasis |
|---|---|---|---|---|
| **EXPLAIN** | Answer "why?" | Educational | ANALYZE | Show code + metrics |
| **PLAN** | Create strategy | Strategic | DECIDE | Show effort estimates |
| **GENERATE** | Create artifacts | Action-oriented | GENERATE | Show diffs |
| **EXECUTE** | Run & validate | Real-time | EXECUTE | Show logs + screenshots |
| **AUDIT** | Export evidence | Formal/legal | REPORT | Show signatures + hashes |

**Mode Switching:**
- User can switch anytime
- Conversation state persisted per mode
- Response format changes automatically

---

## 4. Invocation Channels

**5 ways users trigger the ChatBot:**

### 1. Contextual (Right-Click)
```
Right-click gap diagnostic
  ‚Üí [Ask RepoSense]
    ‚îú‚îÄ Explain This Gap
    ‚îú‚îÄ Generate Test
    ‚îú‚îÄ Suggest Fix
    ‚îî‚îÄ Show Impact
```

### 2. TreeView-Driven (Buttons)
```
Gap TreeView node
  ‚Üí [üí¨] [üß™] [üõ†] [‚ñ∂]
    ‚îî‚îÄ Action buttons on each node
```

### 3. Command Palette
```
Ctrl+Shift+P
  ‚Üí "RepoSense: Generate Tests"
  ‚Üí "RepoSense: Explain Gaps"
  ‚Üí "RepoSense: Run Validation"
```

### 4. Chat UI (Free-Form)
```
ChatBot WebView:
  Type: "Why is this endpoint unused?"
  ‚Üí ChatBot classifies intent + responds
```

### 5. Automatic (System Events)
```
After gap analysis completes
  ‚Üí ChatBot shows: "Found 12 gaps, 3 CRITICAL"
  ‚Üí Offers [Generate Tests] button
```

---

## 5. Safety & Governance

### Action Classification

**Tier 1: Safe (Read-Only)** ‚úÖ
- No confirmation needed
- Examples: EXPLAIN, DECIDE, EXPORT
- Examples: "Explain gaps", "Show coverage"

**Tier 2: Medium (Modifications)** ‚ö†Ô∏è
- Diff shown automatically
- User confirmation required
- Rollback possible
- Examples: GENERATE, APPLY_TESTS

**Tier 3: High (Destructive)** üî¥
- Double confirmation required
- User must type confirmation text
- Immutable audit trail
- Examples: DELETE_ENDPOINT

### Confirmation Flow

**Tier 2 Example: Generate Tests**
```
1. ChatBot generates candidates
2. Shows: "Create 3 test files" + [Show Diff]
3. User clicks [Show Diff]
4. ChatBot shows side-by-side comparison
5. User clicks [Apply]
6. Files written + logged
```

**Tier 3 Example: Delete Endpoint**
```
1. ChatBot: "‚ö†Ô∏è Delete code"
2. Shows impact: "Referenced in 7 files"
3. User clicks [Show Impact]
4. ChatBot shows affected code
5. User clicks [Still Delete]
6. ChatBot: "Type DELETE to confirm"
7. User types "DELETE"
8. Code deleted + audit logged
```

### Audit Trail

Every action logged to `.reposense/runs/<runId>/audit.log`:

```json
{
  "timestamp": "2026-01-21T15:30:45Z",
  "action": "GENERATE_TESTS",
  "actor": "user@example.com",
  "target": "gapId:abc123",
  "result": "SUCCESS",
  "artifactsCreated": 3,
  "confirmation": {
    "required": true,
    "confirmed": true,
    "duration": "4.877s"
  }
}
```

---

## 6. Guaranteed UX Patterns

**Pattern 1: Always Show Diff First**
```
BEFORE: Generic "Would you like to generate tests?"
AFTER: [Diff] ‚Üí [Apply] ‚Üí Files created

Result: User can see exact changes before applying
```

**Pattern 2: Never Auto-Apply**
```
BEFORE: "I'll fix this for you" ‚Üí code modified
AFTER: "I'll suggest this fix" ‚Üí [Show Diff] ‚Üí [Apply]

Result: Full user control, no surprises
```

**Pattern 3: Evidence Everything**
```
BEFORE: "Tests ran successfully"
AFTER: "‚úÖ 15/15 passed" + [View Logs] + [Screenshots] + [Video]

Result: Compliance-grade evidence chain
```

**Pattern 4: Conversational Continuity**
```
BEFORE: Separate commands (analyze, generate, run)
AFTER: One conversation spanning all steps

Result: Coherent workflow, clear evidence
```

---

## 7. Architecture Integration

### Where ChatBot Fits

```
VS Code Extension Host
  ‚îú‚îÄ ChatBotPanel (WebView UI)
  ‚îú‚îÄ ChatBotService (Intent routing + action planning)
  ‚îÇ   ‚îú‚îÄ IntentClassifier (Pattern + NLP)
  ‚îÇ   ‚îú‚îÄ ActionPlanner (Intent ‚Üí Actions)
  ‚îÇ   ‚îî‚îÄ ActionExecutor (Actions ‚Üí Tools)
  ‚îî‚îÄ RunOrchestrator (Executes actions)
      ‚îú‚îÄ AnalysisEngine
      ‚îú‚îÄ TestGenerationService
      ‚îú‚îÄ TestExecutor
      ‚îî‚îÄ ReportGenerator
```

### Service Dependencies

```
ChatBotService
  ‚îî‚îÄ Depends on:
     ‚îú‚îÄ RunOrchestrator
     ‚îú‚îÄ TestGenerationService
     ‚îú‚îÄ TestExecutor
     ‚îú‚îÄ ReportGenerator
     ‚îú‚îÄ OllamaService
     ‚îî‚îÄ GovernanceService (diffs, confirmations, audit)
```

### Data Flow

```
User Input
  ‚Üì
ChatBotService.processUserInput()
  ‚îú‚îÄ classifyIntent() ‚Üí ChatIntent
  ‚îú‚îÄ planActions() ‚Üí ChatAction[]
  ‚îú‚îÄ executeActions() ‚Üí ChatActionResult[]
  ‚îî‚îÄ renderResponse() ‚Üí ChatMessage
```

---

## 8. Implementation Roadmap

### Phase 1: Intent Classification (Week 1)
- [x] Define intent patterns
- [ ] Implement pattern-based classifier
- [ ] Add NLP classifier (Ollama)
- [ ] Test intent recognition

### Phase 2: Action Planning (Week 2)
- [ ] Implement planActions() for each intent
- [ ] Add action sequencing
- [ ] Test action ordering

### Phase 3: Tool Coordination (Week 2)
- [ ] Implement executeActions()
- [ ] Bridge to RunOrchestrator
- [ ] Add error handling

### Phase 4: WebView UI (Week 3)
- [ ] Design chat panel
- [ ] Implement message rendering
- [ ] Add mode selector
- [ ] Test interactivity

### Phase 5: Invocation Points (Week 3)
- [ ] Add right-click context menu
- [ ] Add TreeView buttons
- [ ] Add Command Palette commands

### Phase 6: Integration & Testing (Week 4)
- [ ] Unit tests
- [ ] Integration tests
- [ ] E2E tests
- [ ] UAT with team

---

## 9. Success Criteria

**When is ChatBot "Done"?**

‚úÖ **Functional**
- [ ] Classifies user input ‚Üí ChatIntent
- [ ] Plans actions ‚Üí ChatAction[]
- [ ] Executes actions ‚Üí Results
- [ ] Renders responses ‚Üí ChatMessage

‚úÖ **Safe**
- [ ] Shows diff before apply
- [ ] Asks confirmation for modifications
- [ ] Never auto-applies
- [ ] Logs every action
- [ ] Supports rollback

‚úÖ **Multi-Channel**
- [ ] Right-click context menu works
- [ ] TreeView buttons work
- [ ] Command Palette works
- [ ] Chat UI works
- [ ] Auto-notifications work

‚úÖ **Multi-Modal**
- [ ] EXPLAIN mode works
- [ ] PLAN mode works
- [ ] GENERATE mode works
- [ ] EXECUTE mode works
- [ ] AUDIT mode works

‚úÖ **Integrated**
- [ ] Coordinates with RunOrchestrator
- [ ] Uses existing services
- [ ] No circular dependencies
- [ ] Persists state correctly

‚úÖ **Tested**
- [ ] Unit test coverage > 80%
- [ ] Integration tests pass
- [ ] E2E tests pass
- [ ] UAT approved

---

## 10. Documentation Files

**All ChatBot specifications are documented in:**

1. **CHATBOT_INTENT_ROUTING.md** ‚Äî Complete intent routing table (E-F analysis)
2. **CHATBOT_CONVERSATION_MODES.md** ‚Äî 5 conversation modes + flow diagrams
3. **CHATBOT_INVOCATION_POINTS.md** ‚Äî 5 invocation channels + examples
4. **CHATBOT_SAFETY_GOVERNANCE.md** ‚Äî Confirmation flows + audit trails
5. **CHATBOT_IMPLEMENTATION_GUIDE.md** ‚Äî Step-by-step implementation phases
6. **CHATBOT_PRODUCT_SPEC.md** ‚Äî This document (overview)

---

## 11. Example End-to-End Scenario

**"I want to fix the critical API gaps and generate evidence"**

```
1. User opens RepoSense
   ‚îî‚îÄ Extension auto-runs analysis
   ‚îî‚îÄ ChatBot shows: "Found 12 gaps, 3 CRITICAL"

2. User right-clicks on CRITICAL gap
   ‚îî‚îÄ Context menu: [Explain This Gap]
   ‚îî‚îÄ ChatBot (EXPLAIN mode): "Missing endpoint called 47 times..."
   ‚îî‚îÄ Mode switches to EXPLAIN
   ‚îî‚îÄ Shows code location + test references

3. User clicks [TreeView: üß™ Generate] on same gap
   ‚îî‚îÄ ChatBot (GENERATE mode): "I'll generate Playwright tests"
   ‚îî‚îÄ Switches to GENERATE mode
   ‚îî‚îÄ Shows diff: +120 lines, 3 test scenarios
   ‚îî‚îÄ User clicks [Apply]
   ‚îî‚îÄ Files written to workspace

4. User types: "Run the tests"
   ‚îî‚îÄ ChatBot classifies: EXECUTE intent
   ‚îî‚îÄ Switches to EXECUTE mode
   ‚îî‚îÄ Asks: "Ready to run 15 tests?"
   ‚îî‚îÄ User confirms
   ‚îî‚îÄ Real-time progress: "Running 15/15..."
   ‚îî‚îÄ Results: ‚úÖ 15/15 PASSED

5. User clicks [TreeView: üìã Evidence] on run result
   ‚îî‚îÄ ChatBot (AUDIT mode): Generates UAT report
   ‚îî‚îÄ Includes: test results, screenshots, execution log, hashes
   ‚îî‚îÄ User clicks [Export]
   ‚îî‚îÄ Archive ready: evidence-2026-01-21.zip

6. User attaches to ticket: "Gap fixed and validated"
```

**Total workflow: 5 minutes**
**Evidence collected: Screenshots, logs, test results, hashes**
**Audit trail: All actions logged**

---

## 12. Competitive Advantages

vs. Manual Testing:
- ‚úÖ Faster (automates plan + generate + run)
- ‚úÖ Safer (diffs + confirmations)
- ‚úÖ More evidence (captures logs, screenshots, videos)

vs. Generic Copilot:
- ‚úÖ Domain-specific (understands gaps, endpoints, tests)
- ‚úÖ Governed (confirmations, audit trails)
- ‚úÖ Evidence-rich (compliance-grade reporting)

vs. CI/CD Pipeline:
- ‚úÖ Interactive (user-guided, not automated)
- ‚úÖ Local (runs in dev environment)
- ‚úÖ Flexible (user chooses what to validate)

---

## 13. Risk Mitigation

**Risk: User accidentally applies wrong fix**
- Mitigation: Always show diff + ask confirmation

**Risk: No audit trail for compliance**
- Mitigation: Log every action to `.reposense/runs/`

**Risk: User can't undo changes**
- Mitigation: Support Ctrl+Z + manual rollback

**Risk: ChatBot goes offline (Ollama crashes)**
- Mitigation: Fall back to pattern-based classification

**Risk: Too many confirmation prompts (friction)**
- Mitigation: 3 safety tiers; Tier 1 = no confirmation

---

## 14. Future Enhancements

**V2.0 Roadmap:**
- Multi-user support (permissions, team workflows)
- Chat history export (compliance reporting)
- Scheduled runs (nightly validation)
- Slack integration (post results to #qa channel)
- Advanced NLP (understands complex queries)
- Custom intents (extensible architecture)

---

## 15. Success Metrics

**When should we consider ChatBot successful?**

1. **Adoption:** 90% of team uses ChatBot weekly
2. **Productivity:** 50% reduction in manual test planning time
3. **Quality:** 100% of API changes covered by generated tests
4. **Compliance:** 0 audit findings related to test evidence
5. **Satisfaction:** NPS > 8.0 from team feedback

---

## Appendix A: Glossary

| Term | Definition |
|---|---|
| **Intent** | User's goal (ANALYZE, DECIDE, GENERATE, EXECUTE, REPORT) |
| **Action** | Discrete system operation (FETCH_GAP, GENERATE_TESTS, RUN_TESTS) |
| **Mode** | Conversation context (EXPLAIN, PLAN, GENERATE, EXECUTE, AUDIT) |
| **Channel** | Invocation method (right-click, TreeView, palette, chat, auto) |
| **Artifact** | Generated file or result (test, screenshot, report, log) |
| **Evidence** | Audit-trail artifacts (logs, screenshots, videos, hashes) |
| **Diff** | Preview of changes before applying |
| **Confirmation** | User approval required (safety tier 2-3) |
| **Audit Trail** | Immutable log of all actions |
| **Rollback** | Undo applied changes |

---

**Status:** ‚úÖ Ready for development team to implement

**Next Steps:**
1. Review this spec with team
2. Start Phase 1 (Intent Classification)
3. Create implementation tickets
4. Begin development (est. 4 weeks)

